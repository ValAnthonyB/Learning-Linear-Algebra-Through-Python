\documentclass[12pt, letterpaper]{article}
\usepackage[margin=1in]{geometry}
\usepackage{amsmath,amsthm,array, amssymb,amsfonts, enumitem, fancyhdr, color, comment, graphicx, environ}


\author{Val Anthony Balagon}
\date{January 2019}
\title{Chapter 3: Vector Spaces and Subspaces}

%User commands
\newcommand{\R}[1]{$\mathbb{R}^{#1}$}
\newcommand{\Vector}[1]{$\textbf{#1}$}
\newcommand{\V}[1]{\textbf{\textit{#1}}}

\newcommand{\A}{$A$}
\newcommand{\x}{\textbf{\textit{x}}}
\newcommand{\B}{\textbf{\textit{b}}}
\newcommand{\system}{\textbf{\textit{\A \x = \B}}}
\newcommand{\nullsystem}{\textbf{\textit{\A \x = 0}}}

\newtheorem*{remark}{Remark}
\theoremstyle{definition}
\newtheorem{definition}{Definition}[section]
\newtheorem{example}{Example}


\newcommand*{\vertbar}{\rule[-1ex]{0.5pt}{2.5ex}}

\newenvironment{problem}[2][Problem]{\begin{trivlist}
		\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}
\newenvironment{sol}
{\emph{Solution:}
}
{
	\qed
}
\specialcomment{com}{ \color{blue} \textbf{Comment:} }{\color{black}} %for instructor comments while grading
\NewEnviron{probscore}{\marginpar{ \color{blue} \tiny Problem Score: \BODY \color{black} }}


\begin{document}
	\maketitle
	\begin{abstract}
		This chapter focuses on vector spaces and subspaces. Topics include vector spaces and subspaces such as the column space $C(A)$, nullspace $N(A)$, and the rest of the \emph{four subspaces}.
	\end{abstract}


\section{The Nullspace of A: Solving $A\textbf{x} = \textbf{0}$ and $R\textbf{x} = \textbf{0}$}
	The nullspace is a subspace of matrix $A$ (square or rectangular) that contains all of the solutions to $A\textbf{x} = \textbf{0}$. A readily available solution to the system is the zero vector \Vector{Z}. Invertible matrices only have the zero vector as a solution while non-invertible matrices have nonzero solutions. \textbf{Each solution \Vector{x} belongs to the nullspace of $A$ which is in \R{n}.}
		
	\begin{problem}{1} 
				Describe the nullspace of the singular matrix $A = \begin{bmatrix}
																		1 & 2 \\
																		3 & 6
																		\end{bmatrix}$.
	\end{problem}
	
	\begin{sol}
		We produce the following from elimination: 
		\begin{gather*}
			A \V{x} = 0  \\
			\begin{bmatrix}
			1 & 2 \\
			0 & 0 
			\end{bmatrix}\begin{bmatrix}
								x_1 \\
								x_2
						\end{bmatrix} =	\begin{bmatrix}
												0 \\
												0 
											\end{bmatrix}
			\intertext{\textbf{Elimination produces a single line}. This line is in the nullspace of $A$ and \textbf{contains all solutions ($x_1, x_2$)}. $x_2$ is a free variable. We choose $x_2 = 1$ as our special solution because all points on the line are multiples to it. From there, we get $x_1=-2$.}
				\V{s} = \begin{bmatrix}
						-2 \\
						1
						\end{bmatrix} \\
			\intertext{Hence,}
							A\V{s} = \begin{bmatrix}
												1 & 2 \\
												3 & 6
											\end{bmatrix} \begin{bmatrix}
															-2 \\
															1
															\end{bmatrix} = \begin{bmatrix}
																					0 \\
																					0
																					\end{bmatrix} \\
		\end{gather*}
	\end{sol}

	The nullspace of $A$ consists of all combinations of the special solutions to $A\V{x}=\textbf{0}$
	
	\begin{problem}{2} 
		$x+2y+3z=0$ comes from the $1 \times 3$ matrix $\begin{bmatrix}
															1 & 2 & 3
														\end{bmatrix}$. Then $A\V{x}=\textbf{0}$ produces a plane. All vectors on the plane are perpendicular to $(1,2,3)$. \textbf{The plane is the nullspace of A}. There are 2 free variables $y$ and $z$: Set to $0$ and $1$.
	\end{problem}

	\begin{sol}
			\begin{gather*}
				A \V{x} = \begin{bmatrix}
				1 & 2 & 3
				\end{bmatrix} \begin{bmatrix}
								x \\
								y \\
								z
								\end{bmatrix} = 0
				\intertext{We have two free variables $y$ and $z$, hence we have two special solutions. For $\textbf{\textit{v}}_1$, we choose $y=1$ and $z=0$.}
					x + 2(1) + 3(0) = 0 \qquad \rightarrow \qquad x = -2 \\
					\V{s}_1 = \begin{bmatrix}
								-2 \\
								1 \\
								0
							\end{bmatrix}
				\intertext{For $\V{s}_2$, we choose $y=0$ and $z=1$. }
					x + 2(0) + 3(1) = 0 \qquad \rightarrow \qquad x = -3 \\
					\V{s}_2 = \begin{bmatrix}
								-3 \\
								0 \\
								1
								\end{bmatrix}
				\intertext{Checking for $\V{s}_1$ and $\V{s}_2$,}
					A \V{s}_1 = \begin{bmatrix}
									1 & 2 & 3
									\end{bmatrix} \begin{bmatrix}
														-2 \\
														1\\
														0
														\end{bmatrix} = -2 + 2 + 0 = 0 \\
				A \V{s}_2 = \begin{bmatrix}
								1 & 2 & 3
								\end{bmatrix} \begin{bmatrix}
												-3 \\
												0 \\
												1
												\end{bmatrix} =	-3 + 0 + 3 = 0
			\end{gather*}
			The vectors $\V{s}_1, \V{s}_2$ lie on the plane $x + 2y + 3z=0$. All vectors on the plane are combinations of $\V{s}_1$ and $\V{s}_2$.
	\end{sol}

	\begin{remark}
		There are two key steps in finding the nullspace of a matrix. 
		\begin{enumerate}
			\item Reducing $A$ to \textbf{row echelon form $R$}
			\item Finding the special solutions to $A\V{x}=\textbf{0}$
		\end{enumerate}
	\end{remark}

\subsection{Pivot Variables and Free Columns}
	Free components correspond to columns with no pivots. The special choice (1 or 0) is only for the free variables in the special solutions.
	
		\begin{problem}{2} 
			Find the nullspaces of the following matrices.
			
			\begin{gather*}
					A =  \begin{bmatrix}
							1 & 2 \\
							3 & 8
						  \end{bmatrix} \qquad  B =  \begin{bmatrix}
													  A \\
													  2A
													  \end{bmatrix} =  \begin{bmatrix}
																			  1 & 2 \\
																			  3 & 8 \\
																			  2 & 4 \\
																			  6 & 16
																			  \end{bmatrix} \qquad  C =  \begin{bmatrix}
																											  A & 2A
																											  \end{bmatrix} =  \begin{bmatrix}
																																  1 & 2 & 2 & 4 \\
																																  3 & 8 & 6 & 16
																																  \end{bmatrix}
			\end{gather*}

	\end{problem}
	
	\begin{sol}
		\begin{gather*}
			\intertext{Elimination with $A$ yields} 
					A =  \begin{bmatrix}
								1 & 2 \\
								3 & 8
								\end{bmatrix} \rightarrow U\V{x} = \begin{bmatrix}
													1 & 2 \\
													0 & 2
													\end{bmatrix} \begin{bmatrix}
																	x_1 \\
																	x_2
																	\end{bmatrix} = \begin{bmatrix}
																						0 \\
																						0
																						\end{bmatrix}
			\intertext{$A$ is an invertible matrix, hence \V{x} = $\begin{bmatrix}
																			0 \\
																			0
																			\end{bmatrix}$. On to $B$.}
					 B = \begin{bmatrix}
						1 & 2 \\
						3 & 8 \\
						2 & 4 \\
						6 & 16
					\end{bmatrix} 	\rightarrow \begin{bmatrix}
													1 & 2 \\
													0 & 2 \\
													2 & 4 \\
													6 & 16
													\end{bmatrix} \rightarrow \begin{bmatrix}
																					1 & 2 \\
																					0 & 2 \\
																					0 & 0 \\
																					0 & 4
																					\end{bmatrix} \rightarrow \begin{bmatrix}
																													1 & 2 \\
																													0 & 2 \\
																													0 & 0 \\
																													0 & 0
																													\end{bmatrix} \\
				U\V{x} = \begin{bmatrix}
				1 & 2 \\
				0 & 2 \\
				0 & 0 \\
				0 & 0
				\end{bmatrix} \begin{bmatrix}
									x_1 \\
									x_2 
									\end{bmatrix} = \begin{bmatrix}
														0 \\
														0 \\
														0\\ 
														0
														\end{bmatrix}
				\intertext{The first two rows do not have special solutions other than the trivial zero vector. The 3rd and 4th rows are dependent on the 1st and 2nd rows, respectively which would become zero rows when we do elimination. The nullspace is \V{x} = $\begin{bmatrix}
																													0 \\
																													0
																													\end{bmatrix}$. On to $C$.}
				C = \begin{bmatrix}
						1 & 2 & 2 & 4 \\
						3 & 8 & 6 & 16
						\end{bmatrix} \rightarrow  \begin{bmatrix}
													1 & 2 & 2 & 4 \\
													0 & 2 & 0 & 4
													\end{bmatrix} \\
				U\V{x} = \begin{bmatrix}
				1 & 2 & 2 & 4 \\
				0 & 2 & 0 & 4
				\end{bmatrix} \begin{bmatrix}
								x_1 \\
								x_2 \\
								x_3 \\
								x_4
								\end{bmatrix} = \begin{bmatrix}
														0 \\
														0
														\end{bmatrix}
				\intertext{The first two columns above are called the ``\textit{pivot columns}" while the last two rows are called ``\textit{free columns}." We will have two special solutions since there are two free variables $x_3$ and $x_4$. For \V{s}$_1$, we choose $x_3=1$ and $x_4=0$.}
				    U \V{s}_1 = \textbf{0} \\ 
				    \begin{bmatrix}
					    1 & 2 & 2 & 4 \\
					    0 & 2 & 0 & 4
					    \end{bmatrix} \begin{bmatrix}
										    x_1 \\
										    x_2 \\
										    1 \\
										    0
										    \end{bmatrix} = \textbf{0} \\
				\intertext{From row 2,}
						0 + 2x_2 + 0 + 0 = 0\\
				\intertext{From row 1,}
						x_1 + 0 + 2 + 0 = 0 \\
						x_1 = -2 \\
				\intertext{Hence,}
					\boxed{\V{s}_1 = \begin{bmatrix}
											-2 \\
											0 \\
											1 \\
											0
											\end{bmatrix}}
				\intertext{We do the same for \V{s}$_2$, but $x_3=0$ and $x_4=1$}
					U \V{s}_2 = \textbf{0} \\ 
					\begin{bmatrix}
					1 & 2 & 2 & 4 \\
					0 & 2 & 0 & 4
					\end{bmatrix} \begin{bmatrix}
									x_1 \\
									x_2 \\
									0\\
									1
									\end{bmatrix} = \textbf{0} \\
				\intertext{From row 2,}
					0 + 2x_2 + 0 + 4 = 0\\
					x_2 = -2
				\intertext{From row 1,}
					x_1 + -4 + 0 + 4 = 0 \\
					x_1 = 0 \\
				\intertext{Hence,}
					\boxed{					
					\V{s}_2 = \begin{bmatrix}	
									0 \\
									-2 \\
									0\\
									1
									\end{bmatrix}}
		\end{gather*}
	\end{sol}

\subsection{Reduced Row Echelon Form $R$}
		We already know how to do Gaussian elimination. To get to RREF, we must produce zeros above the pivots of $U$ and produce ones in the pivots of $U$ by using pivot rows to eliminate upward in $R$ and dividing the whole pivot row by its own pivot. The unique thing is that the nullspace does not change throughout the elimination process: $\textbf{N(A) = N(U) = N(R)}.$
		
		
		\begin{gather*}
			U = \begin{bmatrix}
				1 & 2 & 2 & 4 \\
				0 & 2 & 0 & 4
			\end{bmatrix} \rightarrow  R = \begin{bmatrix}
												1 & 0 & 2 & 0 \\
												0 & 1 & 0 & 2
											\end{bmatrix} \\
			R\V{x} = \textbf{0} \\
			\begin{bmatrix}
			1 & 0 & 2 & 0 \\
			0 & 1 & 0 & 2
			\end{bmatrix} \begin{bmatrix}	
							x_1 \\
							x_2 \\
							x_3 \\
							x_4
							\end{bmatrix} = \begin{bmatrix}	
												0 \\
												0
												\end{bmatrix}
		\intertext{When we reach $R$, getting the special solutions become easier. \V{s}$_1= (-2,0,1,0)$ and \V{s}$_2=(0, -2, 0, 1)$}
		\end{gather*}
		
		Many matrices only have one solution to $A\V{x} = 0$, the zero vector \V{Z}. The nullspaces of these matrices become $N(A)=\V{Z}$ without any special solutions. This case stresses the notion that $A$'s columns are \textbf{independent}. No combination of columns gives the zero vector except for the zero combination. All columns are pivots and there are no free columns. Below is another example.
		
		\begin{problem}{3}
			What are the special solutions of the following $4\times 5$ matrix?
				$A = \left[\begin{array}{ccccc}
				\vertbar & \vertbar &  \vertbar & \vertbar & \vertbar \\
				p        &     p    &      f    &    p     &    f    \\
				\vertbar & \vertbar &  \vertbar & \vertbar & \vertbar 
				\end{array}\right]$
		\end{problem}
	
		\begin{sol}
			\begin{gather*}
				\intertext{Using elimination and doing RREF(A), we eventually reach $R$}
						\V{R} = \begin{bmatrix}
								\textbf{1} & 0 & a & 0 & c \\
								0 & \textbf{1} & b & 0 & d \\
								0 & 0 & 0 & \textbf{1}& e \\
								0 & 0 & 0 & 0 &0
								\end{bmatrix}
				\intertext{There are only 2 free columns, therefore there are only 2 free variables. We will need $\V{s}_1 \text{and} \,\V{s}_2$. For \V{s}$_1$, we choose $x_3=1$ and $x_5=0$. For \V{s}$_2$, we choose $x_3=0$ and $x_5=1$.}
					\V{s}_1 = \begin{bmatrix}	
									-a \\
									-b \\
									1 \\
									0 \\
									0
									\end{bmatrix},
									\qquad
									\V{s}_2= \begin{bmatrix}	
												-c \\
												-d \\
												0 \\
												-e \\
												1
												\end{bmatrix}
			\end{gather*}
		\end{sol}
	
	\begin{remark}
		The example above is a short wide matrix where $n>m$ (there are more columns than rows). These systems lead to at least 1 free variable. \textbf{There are exactly $n-m$ free variables if $n>m$}.	
	\end{remark}

\subsection{Rank of a Matrix}
	\textbf{The \textit{size} of a matrix $A$ is the rank $r$}. The rank is the number of pivot columns in $A$. Elimination allows us to see the rank the matrix.
	
		\begin{gather*}
			A = \begin{bmatrix}
						1 & 1 & 2 & 4 \\
						1 & 2 & 2 & 5 \\
						1 & 3 & 2 & 6
				\end{bmatrix} \rightarrow R = \begin{bmatrix}
												1 & 0 & 2 & 3 \\
												0 & 1 & 0 & 1 \\
												0 & 0 & 0 & 0
												\end{bmatrix}
		\end{gather*}
		
		Here we see that column 2 is simply 2(column 1). Via elimination, we see that there are $2$ pivot columns (columns 1 and 2) and 2 free columns (columns 3 and 4). Hence, the rank of $A$ is 2.
		
\subsubsection{Rank One}
	A rank one matrix has only one pivot column. When we use elimination, we see that every row is a multiple of the pivot row.
	
	\begin{gather*}
			A = \begin{bmatrix}
					1 & 3 & 10 \\
					2 & 6 & 20 \\
					3 & 9 & 30
					\end{bmatrix} \rightarrow R = \begin{bmatrix}
														1 & 3 & 10 \\
														0 & 0 & 0 \\
														0 & 0 & 0
														\end{bmatrix}
	\end{gather*}
	
	The column space of a rank-one matrix is ``one-dimensional." Here all columns are on the line through $\V{u}=(1,2,3)$. The columns of $A$ are $\V{u}, 3\V{u}$, and $10\V{u}$. We take the first row of $R$ into a row vector $v^T = \begin{bmatrix} 1 & 3 & 10 \end{bmatrix}$ and we have a special rank one form $A=\V{uv}^T$:
				
				\begin{gather*}
					A = \V{uv}^T = \begin{bmatrix} 1 \\ 2 \\ 3 \end{bmatrix} \begin{bmatrix} 1 & 3 & 10 \end{bmatrix}
				\end{gather*}
				
	With rank one, the system $A\V{x} = 0$ is easy to understand. From the equation above, we get $\V{u}(\V{v}^T \V{x})=0$ which leads us to $\V{v}^T \V{x} = 0$. This says that all vectors $\V{x}$ in the nullspace must be orthogonal to $\V{v}$ in the row space. Here are additional examples.
	
	
	\begin{gather*}
	A = \begin{bmatrix}
			1 & 3 & 4 \\
			2 & 6 & 8 
			\end{bmatrix}, \qquad B = \begin{bmatrix}
											0 & 3 \\
											0 & 5
											\end{bmatrix} \\
	\intertext{For $A$,}
		RREF(A) = \begin{bmatrix}
					1 & 3 & 4 \\
					0 & 0 & 0
					\end{bmatrix} \\
		A = \begin{bmatrix} 1\\ 2 \end{bmatrix} \begin{bmatrix} 1 & 3 & 4 \end{bmatrix} \\
	\intertext{For $B$,}
		RREF(B) = \begin{bmatrix}
					0 & 1 \\
					0 & 0
					\end{bmatrix} \\
		B = \begin{bmatrix} 3\\ 5 \end{bmatrix} \begin{bmatrix} 0 & 1 \end{bmatrix}
	\end{gather*}
	
	The \textbf{rank is the number of independent columns and rows in} $A$. $A, U,$ and $R$ have $r$ independent columns and rows. The rank is also the dimension of the column space and rowspace. The nullspace has a dimension of $\V{n} - \V{r}$.
	
	
\section{The Complete Solution to $A\V{x} = \V{b}$}
	In this chapter, \V{b} is not zero. Which means that elimination also affects \V{b}. To make elimination easier, we make an augmented matrix by adding an extra column \V{b} to $A \rightarrow \begin{bmatrix} A & \V{b}\end{bmatrix}$.
	
		\begin{gather*}
			A = \begin{bmatrix}
			1&3&0&2\\
			0&0&1&4\\
			1&3&1&6
			\end{bmatrix}, \qquad \V{b} = \begin{bmatrix} 1 & 6 & 7 \end{bmatrix} \\
		\intertext{Augmented matrix:}
			\begin{bmatrix} A & \V{b}\end{bmatrix} = \begin{bmatrix}
														1&3&0&2 & \textbf{1}\\
														0&0&1&4 & \textbf{6}\\
														1&3&1&6 & \textbf{7}
													\end{bmatrix}
		\end{gather*}
	
	
\subsection{One Particular Solution $A\V{x}_p = \V{b}$}
	For an easy solution $\V{x}_p$, we choose $x_2$ and $x_4$ to be zero. Then the pivot variables $x_1$ and $x_3$ become $\V{b}$ ($x_1=1$ and $x_3=6$). Our particular solution becomes $\V{x}_p = (1,0,6,0)$
	
		\begin{gather*}
			R\V{x}_p = \V{d} \\
			\begin{bmatrix}
					1&3&0&2\\
					0&0&1&4\\
					0&0&0&0
				\end{bmatrix} \begin{bmatrix}\textbf{1} \\
											  0 \\
											  \textbf{6} \\
											  0 \end{bmatrix} = \begin{bmatrix}
											  						\textbf{1} \\ \textbf{6} \\ 0
											  					\end{bmatrix}
		\end{gather*} 
	
	
	When the free variables are zero, the pivot variables for $\V{x}_p$ are readily seen in the right side vector $\V{d}$. There are 2 free variables in $A$, hence there are 2 special solutions $\V{s}_1, \V{s}_2$ to the nullspace.
	
	
	\begin{gather*}
		\V{s}_1 = \begin{bmatrix} -3 \\ 1\\ 0 \\ 0 \end{bmatrix}, \qquad \V{s}_2 = \begin{bmatrix} -2 \\ 0\\ -4 \\ 1 \end{bmatrix}
	\intertext{The complete solution becomes:}
		A \V{x} = \V{b}\\ 
		A(\V{x}_p + \V{x}_n) = \begin{bmatrix}
											1&3&0&2\\
											0&0&1&4\\
											0&0&0&0
											\end{bmatrix} \left( x_2\begin{bmatrix} -3 \\ 1\\ 0 \\ 0 \end{bmatrix} + x_4\begin{bmatrix} -2 \\ 0\\ -4 \\ 1 \end{bmatrix} \right) = \begin{bmatrix}
											\textbf{1} \\ \textbf{6} \\ 0
											\end{bmatrix}
	\intertext{Where $x_2$ and $x_4$ can be any real number.}
	\end{gather*}
	
	The only solution to a full rank invertible matrix ($m=n=r$) is $\V{x}_p$ since there are no nullspace special solutions. Here $\V{x}_p = A^{-1}\V{b}$. The next example is with \textit{full column rank}.
		\begin{gather*}
			A = \begin{bmatrix}
						1&1\\
						1&2\\
						-2&-3
						\end{bmatrix}, \qquad \V{b} = \begin{bmatrix} b_1 & b_2 & b_3 \end{bmatrix}
		\intertext{$\begin{bmatrix} A & \V{b}\end{bmatrix} \rightarrow \begin{bmatrix} R & \V{d}\end{bmatrix}$}
			\begin{bmatrix} R & \V{d}\end{bmatrix} = \begin{bmatrix}
																1 & 0 & \textbf{2b$_1$ - b$_2$}\\
																0 & 1 & \textbf{b$_2$ - b$_1$}\\
																0 & 0 & \textbf{b$_3$ + b$_1$ + b$_2$}
																\end{bmatrix}
		\end{gather*}
		
		This example has no free variables since $n-r=0$. This also means that the nullspace solution is $\V{x} = \textbf{0}$. $A$ has full column rank and all columns are pivot columns. The rank is $r=n$. The matrix is tall and thin ($m \ge n$). Row reduction puts $I$ at the top of $R$.
		
			$$R = \begin{bmatrix}
					I \\ 0
				\end{bmatrix} = \begin{bmatrix}
									n \times n \text{ \,identity matrix}\\m - n \text{ \,rows of zeros}
									\end{bmatrix}$$
	
	\noindent With full column rank, $A\V{x} = \V{b}$ has one solution or no solution ($m>n$ is an \textit{overdetermined} system). Here are some properties of full column rank matrices: 
		\begin{enumerate}
			\item All columns are pivot columns
			\item There are no free variables or special solutions
			\item The nullspace $N(A)$ contains only the zero vector.
			\item If $A\V{x} = \V{b}$ has a solution (it might not) then it has only one solution $\V{x}_p$.
		\end{enumerate}
	
	Another example is full row rank. $A\V{x} = \V{b}$ has \textit{one or infinitely many solutions}. $A$ is short and wide ($m \le n$). A matrix is full row rank if $r=m$. The rows are independent in this system and each row has a pivot.
		\begin{gather*}
			\intertext{This system $A\V{x}=\V{b}$ has $n=3$ unknowns but with only $m=2$ equations}
				A = \begin{bmatrix}
					1 & 1 & 1\\
					1 & 2 & -1
				\end{bmatrix}, \qquad \V{b} = \begin{bmatrix}
												3 \\ 4
												\end{bmatrix}
			\intertext{$\begin{bmatrix} A & \V{b}\end{bmatrix} \rightarrow \begin{bmatrix} R & \V{d}\end{bmatrix}$. The form of $R$ is $\begin{bmatrix} I & F\end{bmatrix}$ where $F$ is/are the free column/s:}
				\begin{bmatrix} R & \V{d}\end{bmatrix} = \begin{bmatrix}
															1 & 0 & 3 & \textbf{2}\\
															0 & 1 & -2 & \textbf{1}
														\end{bmatrix}
			\intertext{We find $\V{x}_p$ from $\V{b}$:}
				\V{x}_p = \begin{bmatrix}
								2 \\ 1 \\ 0
							\end{bmatrix}
			\intertext{There is 1 free column, hence $x_3$ is a free variable}
				\V{s}_1 = \begin{bmatrix}
								-3 \\ 2 \\ 1
							\end{bmatrix}
			\intertext{Hence, the complete solution is:}
				A\V{x} = A(\V{x}_p + \V{x}_n) = \V{b} \\
				\begin{bmatrix}
				1 & 1 & 1\\
				1 & 2 & -1
				\end{bmatrix}\left(\begin{bmatrix} 2 \\ 1 \\ 0 \end{bmatrix} + x_3 \begin{bmatrix} -3 \\ 2 \\ 1 \end{bmatrix} \right) = \begin{bmatrix}
																																			3 \\ 4
																																			\end{bmatrix}
			\intertext{Where $x_3$ is any arbitrary constant.}
		\end{gather*}
		
		\noindent A matrix with full row rank ($r=m$) has all these properties:
			\begin{enumerate}
				\item All rows have pivots, and $R$ has no zeros
				\item $A\V{x} = \V{b}$ has a solution for every right side $\V{b}$
				\item The column space is the whole space \R{m}
				\item There are $n - r = n - m$ special solutions in the nullspace of $A.$
			\end{enumerate}
\subsection{The Complete Solution}
	To summarize, 
	$$
	\begin{array}{llcl}
		\V{r} = \V{m}, \V{r}=\V{n} & \text{Square and invertible} & \system  & \text{Has one solution (nullspace = \V{Z})}\\
		\V{r}=\V{m}, r<n &  \text{Short and wide (underdetermined)} & \system & \text{Has $\infty$ solutions}\\
		r<m, \V{r}=\V{n} &  \text{Tall and thin (overdetermined)} & \system & \text{Has 0 or 1 solution}\\
		r<m, r<n &  \text{Not full rank} & \system & \text{Has 0 or $\infty$ solutions}
	\end{array} 
	$$
	
	\noindent \A\, is the same as $R$ since their column space and nullspace are the same. 
	$$
	\begin{array}{lcccc}
		\text{Four types of $R$} & \begin{bmatrix} I \end{bmatrix}  & \begin{bmatrix} I & F \end{bmatrix} & \begin{bmatrix} I \\ 0 \end{bmatrix} & \begin{bmatrix} I & F \\ 0 & 0 \end{bmatrix}\\
		\text{Their ranks} & r = m = n & r = m < n & r = n < m & r < m, r < n
	\end{array} 
	$$

\section{Independence, Basis, and Dimension}
	The true dimension of the column space of $A$ is measured by counting the number of independent columns which is the rank $r$. Basis vectors are independent vectors that \textbf{span} the space and this means that every vector in the space is a unique combination of the basis vectors.
	
	
\subsection{Linear Independence}
		\begin{definition}
			The columns of $A$ are linearly independent when the only solution to $\nullsystem$ is $\V{x} = \textbf{0}$. No other combination $A\V{x}$ gives the zero vector.
		\end{definition}
	
		The columns are independent when the nullspace $N(A)$ contains only the zero vector.
	
		\begin{definition}
			The sequence of vectors $\V{v}_1, \V{v}_2, \ldots \V{v}_n$ is linearly dependent if the only combination that gives the zero vector is $0\V{v}_1 + 0\V{v}_2 + \ldots 0\V{v}_n$. If the combination $A\V{x}$ gives \textbf{0} when the $x$'s are not all zero, the vectors are dependent.
			
			\begin{gather*}
				x_1 \V{v}_1+ x_2 \V{v}_2 + \ldots + x_n \V{v}_n = \textbf{0} \quad \text{only happens when all $x$'s are zero.}
			\end{gather*}
		\end{definition}
	
	A way to describe linear dependence is: ``\textit{One vector is a combination of other vectors}." 	
	
\subsection{Vectors that Span a Subspace}
		The column space is spanned by the columns of a matrix. The columns of a matrix span its column space and they might be dependent or independent.
					\begin{definition}
						A set of vectors \textbf{\textit{spans}} a space if their linear combinations fill the space.
					\end{definition}
		
				
					\begin{example}
						\begin{gather*}
							\V{v}_1 = \begin{bmatrix}1 \\ 0 \end{bmatrix} \quad \text{and} \quad \V{v}_2 = \begin{bmatrix}0 \\ 1 \end{bmatrix} \text{span the full 2-D space \R{2}}
						\end{gather*}
					\end{example}
				
					\begin{example}
						\begin{gather*}
							\V{v}_1 = \begin{bmatrix}1 \\ 0 \end{bmatrix}, \quad \V{v}_2 = \begin{bmatrix}0 \\ 1 \end{bmatrix} \quad \text{and} \quad \V{v}_3 = \begin{bmatrix}4\\ 7 \end{bmatrix} \text{also span the full 2-D space \R{2}}
						\end{gather*}
					\end{example}
				
					\begin{example}
						\begin{gather*}
							\V{w}_1 = \begin{bmatrix}1 \\ 1 \end{bmatrix} \text{and} \quad \V{w}_2 = \begin{bmatrix}-1 \\ -1 \end{bmatrix} \text{only span a line in \R{2}. So does $\V{w}_1$ by itself.}
						\end{gather*}
					\end{example}
	
	
		
	\noindent The combinations of the rows produce the ``\textbf{\textit{row space}}."
		\begin{definition}
			The row space of a matrix is the subspace \R{n} spanned by the rows.
				\begin{gather*}
					\text{\textbf{The row space of $A$ is $C(A^T)$. It is the column space of $A^T$}}
				\end{gather*}
		\end{definition}
	
				\begin{example}
					Describe the column space and row space of $A$.
					\begin{gather*}
					A = \begin{bmatrix}1&4\\ 2&7 \\ 3&5 \end{bmatrix} \quad \text{and} \quad A^T = \begin{bmatrix}1&2&3 \\ 4&7&5\end{bmatrix}
					\end{gather*}
					
					The $C(A)$ is the plane in \R{3} spanned by the two columns of $A$. The $C(A^T)$ is spanned by the three rows of $A$. This row space is all of \R{2}. Remember: \textit{The rows are in \R{n} spanning the row space, while the columns are in \R{m} spanning the column space.}
				\end{example}
	
	
	
	
\subsection{A Basis for a Vector Space}
		Two vectors can't span all of \R{3}, even if they are independent (because they only span a plane). Four vectors can't be independent, even if they span \R{3}. We want enough independent vectors to span the space (no more no less). A ``\textbf{basis}" is just right. The basis vectors are linearly independent vectors.
		
			 
			 \begin{example}
			 	What are the basis vectors for $I = \begin{bmatrix} 1 & 0 \\ 0 & 1\end{bmatrix}$.
			 	\begin{gather*}
			 		\intertext{$I$ is already in RREF. Hence the column are the basis vectors.}
			 			\V{i} =  \begin{bmatrix} 1 \\ 0\end{bmatrix} \text{and } \V{j} =  \begin{bmatrix} 0 \\ 1\end{bmatrix} \text{are the basis vectors for $I$. These vectors span \R{2}.}
			 	\end{gather*}
			 	If this were a $3 \times 3$ full rank matrix, we would have 3 basis vectors $\V{i}, \V{j}, \text{and } \V{k}$
			 \end{example}
	
	
		\begin{definition}
			\textbf{The pivot columns of $A$ are a basis for its column space. The pivot rows of $A$ are a basis for its row space and so are the pivot rows of its echelon form $R$.}
		\end{definition}
	
		\begin{example}
			What are the basis vectors for $C(A) \text{and } C(A^T)$?
				$$\begin{bmatrix} 2 & 4 \\ 3 & 6 \end{bmatrix}$$
				
				\begin{gather*}
					\intertext{A $\rightarrow$ R:}
						R = \begin{bmatrix} 1 & 2 \\ 0 & 0 \end{bmatrix}
				\end{gather*}
			
			\noindent Hence the basis for the column space is the pivot column of $A$.
				\begin{equation*}
					\text{Basis for } C(A) = \begin{bmatrix} 2 \\ 3 \end{bmatrix}
				\end{equation*}
				
			\noindent The basis for the row space is the pivot row in $R$.
				\begin{equation*}
					\text{Basis for } C(A^T) = \begin{bmatrix} 1 \\ 2 \end{bmatrix}
				\end{equation*}
		\end{example}
	
	
		\begin{definition}
			The dimension of a space is the number of vectors in a basis.
		\end{definition}
	
	
	
	
\end{document}